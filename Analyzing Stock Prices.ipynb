{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this guided project, we'll work with stock market data that was downloaded from Yahoo Finance using the yahoo_finance Python package. This data consists of the daily stock prices from 2007-1-1 to 2017-04-17 for several hundred stock symbols traded on the NASDAQ stock exchange, stored in the prices folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "# Read all CSV files from a folder and combine the data\n",
    "for fn in os.listdir(\"prices\"):\n",
    "    name = fn.split('.')[0]\n",
    "    df[name] = pd.read_csv(os.path.join(\"prices\", fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-03</td>\n",
       "      <td>83.800002</td>\n",
       "      <td>86.289999</td>\n",
       "      <td>86.579999</td>\n",
       "      <td>81.899999</td>\n",
       "      <td>309579900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-04</td>\n",
       "      <td>85.659998</td>\n",
       "      <td>84.050001</td>\n",
       "      <td>85.949998</td>\n",
       "      <td>83.820003</td>\n",
       "      <td>211815100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-05</td>\n",
       "      <td>85.049997</td>\n",
       "      <td>85.770000</td>\n",
       "      <td>86.199997</td>\n",
       "      <td>84.400002</td>\n",
       "      <td>208685400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-08</td>\n",
       "      <td>85.470000</td>\n",
       "      <td>85.959998</td>\n",
       "      <td>86.529998</td>\n",
       "      <td>85.280003</td>\n",
       "      <td>199276700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-09</td>\n",
       "      <td>92.570003</td>\n",
       "      <td>86.450003</td>\n",
       "      <td>92.979999</td>\n",
       "      <td>85.150000</td>\n",
       "      <td>837324600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>143.169998</td>\n",
       "      <td>143.600006</td>\n",
       "      <td>143.880005</td>\n",
       "      <td>142.899994</td>\n",
       "      <td>18473000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>2017-04-11</td>\n",
       "      <td>141.630005</td>\n",
       "      <td>142.940002</td>\n",
       "      <td>143.350006</td>\n",
       "      <td>140.059998</td>\n",
       "      <td>30275300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>2017-04-12</td>\n",
       "      <td>141.800003</td>\n",
       "      <td>141.600006</td>\n",
       "      <td>142.149994</td>\n",
       "      <td>141.009995</td>\n",
       "      <td>20238900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>2017-04-13</td>\n",
       "      <td>141.050003</td>\n",
       "      <td>141.910004</td>\n",
       "      <td>142.380005</td>\n",
       "      <td>141.050003</td>\n",
       "      <td>17652900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>2017-04-17</td>\n",
       "      <td>141.830002</td>\n",
       "      <td>141.479996</td>\n",
       "      <td>141.880005</td>\n",
       "      <td>140.869995</td>\n",
       "      <td>16424000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2590 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date       close        open        high         low     volume\n",
       "0     2007-01-03   83.800002   86.289999   86.579999   81.899999  309579900\n",
       "1     2007-01-04   85.659998   84.050001   85.949998   83.820003  211815100\n",
       "2     2007-01-05   85.049997   85.770000   86.199997   84.400002  208685400\n",
       "3     2007-01-08   85.470000   85.959998   86.529998   85.280003  199276700\n",
       "4     2007-01-09   92.570003   86.450003   92.979999   85.150000  837324600\n",
       "...          ...         ...         ...         ...         ...        ...\n",
       "2585  2017-04-10  143.169998  143.600006  143.880005  142.899994   18473000\n",
       "2586  2017-04-11  141.630005  142.940002  143.350006  140.059998   30275300\n",
       "2587  2017-04-12  141.800003  141.600006  142.149994  141.009995   20238900\n",
       "2588  2017-04-13  141.050003  141.910004  142.380005  141.050003   17652900\n",
       "2589  2017-04-17  141.830002  141.479996  141.880005  140.869995   16424000\n",
       "\n",
       "[2590 rows x 6 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['aapl']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257.1765404023166"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average closing price\n",
    "df_mean_close = {}\n",
    "for name in df:\n",
    "    df_mean_close[name] = df[name]['close'].mean()\n",
    "    \n",
    "df_mean_close['aapl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blfs has the minimum average colsing price: 0.8122763011583011\n"
     ]
    }
   ],
   "source": [
    "# Minimum average closing price\n",
    "stock = 'aapl'\n",
    "for name in df:\n",
    "    if df_mean_close[name] < df_mean_close[stock]:\n",
    "        stock = name\n",
    "        \n",
    "print('{} has the minimum average colsing price: {}'.format(\n",
    "    stock, df_mean_close[stock]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amzn has the maximum average colsing price: 275.13407757104255\n"
     ]
    }
   ],
   "source": [
    "# Minimum average closing price\n",
    "stock = 'aapl'\n",
    "for name in df:\n",
    "    if df_mean_close[name] > df_mean_close[stock]:\n",
    "        stock = name\n",
    "        \n",
    "print('{} has the maximum average colsing price: {}'.format(\n",
    "    stock, df_mean_close[stock]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trade volume\n",
    "\n",
    "We'll calculate a dictionary where the keys are the dates and the values are a list of all trades from all stock symbols that occurred on that day. More precisely, for each day, we'll want a list of pairs (volume, stock_symbol) of all trades that occurred on that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_trans = {}\n",
    "for name in df:\n",
    "    for index, row in df[name].iterrows():\n",
    "        date = row['date']\n",
    "        volume = row['volume']\n",
    "        if date not in daily_trans:\n",
    "            daily_trans[date] = []\n",
    "        daily_trans[date].append([volume, name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_traded_stock = {}\n",
    "for date in daily_trans:\n",
    "    # sort stock by volume, 1st column\n",
    "    daily_trans[date].sort()\n",
    "    most_traded_stock[date] = daily_trans[date][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[309579900, 'aapl']\n",
      "[211815100, 'aapl']\n",
      "[208685400, 'aapl']\n",
      "[199276700, 'aapl']\n"
     ]
    }
   ],
   "source": [
    "print(most_traded_stock['2007-01-03'])\n",
    "print(most_traded_stock['2007-01-04'])\n",
    "print(most_traded_stock['2007-01-05'])\n",
    "print(most_traded_stock['2007-01-08'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily total traded volume\n",
    "total_traded_daily = []\n",
    "for date in daily_trans:\n",
    "    total_volume = sum([volume for volume, _ in daily_trans[date]])\n",
    "    total_traded_daily.append([total_volume, date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1533363200, '2008-01-24'],\n",
       " [1536176400, '2008-01-16'],\n",
       " [1553880500, '2007-11-08'],\n",
       " [1555072400, '2008-09-29'],\n",
       " [1559032100, '2008-02-07'],\n",
       " [1578877700, '2008-01-22'],\n",
       " [1599183500, '2008-10-08'],\n",
       " [1611272800, '2007-07-26'],\n",
       " [1770266900, '2008-10-10'],\n",
       " [1964583900, '2008-01-23']]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 most trade volume dates\n",
    "total_traded_daily.sort()\n",
    "total_traded_daily[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price difference\n",
    "\n",
    "In this part, we will investigate which stock is the most and least profitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_list = []\n",
    "for stock in df:\n",
    "    start_price = df[stock]['close'].iloc[0]\n",
    "    end_price = df[stock]['close'].iloc[-1]\n",
    "    profit_perc = (end_price-start_price)/start_price*100\n",
    "    profit_list.append([profit_perc, stock, start_price, end_price])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1330.0000666666667, 'achc', 3.0, 42.900002],\n",
       " [1339.2137535980346, 'bcli', 0.280014, 4.03],\n",
       " [1525.1625162516252, 'cui', 0.279972, 4.55],\n",
       " [1549.6700659868025, 'apdn', 0.10002, 1.65],\n",
       " [1707.3554472785033, 'anip', 2.800224, 50.610001000000004],\n",
       " [2230.7234281466817, 'amzn', 38.700001, 901.98999],\n",
       " [2437.4365640858978, 'blfs', 0.080002, 2.03],\n",
       " [3898.60048982856, 'arcw', 0.100035, 4.0],\n",
       " [4005.0000000000005, 'adxs', 0.2, 8.21],\n",
       " [7483.8389225948395, 'admp', 0.059996, 4.55]]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profit_list.sort()\n",
    "profit_list[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 10 most profitable have more than 1000% grown. admp has the highest profitable among all, with a increse of 7483.8% from 0.059996."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-98.33424353725407, 'bont', 36.619999, 0.61],\n",
       " [-98.25072886297376, 'dcth', 3.43, 0.06],\n",
       " [-97.52144899904671, 'cmls', 10.49, 0.26],\n",
       " [-96.17224880382774, 'falc', 8.36, 0.32],\n",
       " [-95.62602538950107, 'cetv', 73.160004, 3.2],\n",
       " [-93.2156371644067, 'atlc', 39.650002, 2.69],\n",
       " [-93.17775158217626, 'bbry', 128.549995, 8.77],\n",
       " [-93.04932704257072, 'evep', 22.299999, 1.55],\n",
       " [-91.1604938271605, 'clmt', 40.5, 3.58],\n",
       " [-91.0659114315139, 'dest', 38.84, 3.47]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 worst trade volume dates\n",
    "profit_list.sort()\n",
    "profit_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, bont shrunk most during 2017 for 98.3% from 36.62. It would have been best to short at the start of the period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After hours trade\n",
    "\n",
    "We will find out which stock has the biggest changes between the closing price and the next day open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_hours_trade = {}\n",
    "\n",
    "for stock in df:\n",
    "    # add after hours trade column\n",
    "    df[stock]['next_open'] = np.roll(df[stock]['open'],-1)\n",
    "    df[stock]['abs_after_hours_trade'] = abs(df[stock]['next_open'] - df[stock]['close'])\n",
    "    \n",
    "    # remove last row for missing after hours trade\n",
    "    for idx, row in df[stock].iloc[:-1].iterrows():\n",
    "        date = row['date']\n",
    "        value = row['abs_after_hours_trade']\n",
    "        if date not in after_hours_trade:\n",
    "            after_hours_trade[date] = []\n",
    "        after_hours_trade[date].append([value, stock])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_after_hours_trade_daily = []\n",
    "\n",
    "for date in after_hours_trade:\n",
    "    after_hours_trade[date].sort()\n",
    "    value = after_hours_trade[date][-1][0]\n",
    "    stock = after_hours_trade[date][-1][1]\n",
    "    max_after_hours_trade_daily.append([value, stock])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2.99999200000002, 'cme'],\n",
       " [2.0699960000000033, 'bbry'],\n",
       " [2.169999999999999, 'dvax'],\n",
       " [2.75, 'celg'],\n",
       " [3.75, 'fcnca']]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_after_hours_trade_daily[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
